#!/usr/bin/env python

from argparse import ArgumentParser
from commands import getstatusoutput
import logging, sys, json, yaml, requests
from requests import RequestException
from yaml import YAMLError
from logging import debug, error, info
from re import search, escape
from os.path import isdir, isfile, realpath, dirname
from os import chmod, remove, chdir, getcwd
from shutil import rmtree
from tempfile import NamedTemporaryFile, mkdtemp
from subprocess import Popen, PIPE, STDOUT
from smtplib import SMTP
from socket import getfqdn
from random import random, choice
from urlparse import urlsplit, urlunsplit

def format(s, **kwds):
  return s % kwds

def rmrf(path):
  try:
    if isdir(path):
      rmtree(path)
    elif isfile(path):
      remove(path)
  except OSError as e:
    debug(format("When deleting %(path)s: %(msg)s (ignored)",
                 path=path, msg=str(e)))

def searchMany(name, exprs):
  if isinstance(exprs, list):
    for e in exprs:
      if search(e, name): return True
  elif exprs == True:
    return True
  return False

def applyFilter(name, includeRules, excludeRules, includeFirst):
  if includeFirst:
    if searchMany(name, includeRules):
      return not searchMany(name, excludeRules)
    else:
      return False
  else:
    if searchMany(name, excludeRules):
      return False
    else:
      if includeRules is None:
        # process exclude first, and no explicit include rule: keep it
        return True
      else:
        return searchMany(name, includeRules)

def runInstallScript(script, dryRun, **kwsub):
  if dryRun:
    debug(format("Dry run: publish script follows:\n" + script, **kwsub))
    return 0
  with NamedTemporaryFile(delete=False) as fp:
    fn = fp.name
    fp.write(format(script, **kwsub))
  chmod(fn, 0700)
  debug(format("Created unpack script: %(file)s", file=fn))
  rv = execute(fn)
  remove(fn)
  debug(format("Unpack script %(file)s returned %(rv)d", file=fn, rv=rv))
  return rv

def execute(command):
  popen = Popen(command, shell=False, stdout=PIPE, stderr=STDOUT)
  linesIterator = iter(popen.stdout.readline, "")
  for line in linesIterator:
    debug(line.strip("\n"))  # yield line
  output = popen.communicate()[0]
  debug(output)
  exitCode = popen.returncode
  return exitCode

def grabOutput(command):
  popen = Popen(command, shell=False, stdout=PIPE, stderr=STDOUT)
  return (popen.returncode, popen.communicate()[0])

def jget(url):
  try:
    return requests.get(url).json()
  except (RequestException, ValueError) as e:
    error(format("Getting %(url)s gave %(msg)s", url=url, msg=str(e)))
    return {}

class RiemannPkgNotify(object):

  def __init__(self, host, port):
    self._currentHost = getfqdn()
    self._host = host
    self._port = int(port)
    self._ttl = 86400 * 2  # 2 days
    try:
      import bernhard
      self.client = bernhard.Client(host=host, port=port)
      self.client.send({ "host": self._currentHost,
                         "state": "ok",
                         "service": "aliPublish started",
                         "ttl": self._ttl,
                         "metric": 1 })
      debug("Sending notifications to Riemann on %s:%d" % (self._host, self._port))
    except Exception as e:
      error("Cannot initialize Riemann connection to %s:%d: %s" % (self._host, self._port, e))
      self._host = None

  def notify(self, state, arch, pkgname, pkgver):
    if not self._host:
      return
    if state not in [ "ok", "warning", "critical" ]:
      raise Exception("RiemannPkgNotify only supports ok, warning, critical states")
    self.client.send({ "host": self._currentHost,
                       "state": state,
                       "service": "aliPublish publish %s %s %s" % (arch, pkgname, pkgver),
                       "ttl": self._ttl,
                       "metric": state == "critical" and 1 or 0 })

class CvmfsServer(object):

  def __init__(self, repository, modulefileTpl, pkgdirTpl, publishScriptTpl, dryRun=False):
    self._inCvmfsTransaction = False
    self._repository = repository
    self._modulefileTpl = modulefileTpl
    self._pkgdirTpl = pkgdirTpl
    self._publishScriptTpl = publishScriptTpl
    self._dryRun = dryRun
    self._countChanges = 0

  def _kw(self, url, arch, pkgName, pkgVer):
    kw =  { "url": url, "package": pkgName, "version": pkgVer, "repo": self._repository,
            "arch": arch }
    kw.update({ "pkgdir": format(self._pkgdirTpl, **kw) })
    kw.update({ "modulefile": format(self._modulefileTpl, **kw) })
    return kw

  def installed(self, arch, pkgName, pkgVer):
    kw = self._kw(None, arch, pkgName, pkgVer)
    debug(format("%(repo)s: checking if %(package)s %(version)s is installed for %(arch)s", **kw))
    return isdir(kw["pkgdir"]) or isfile(kw["modulefile"])

  def install(self, url, arch, pkgName, pkgVer, deps, allDeps):
    kw = self._kw(url, arch, pkgName, pkgVer)
    rv = runInstallScript(self._publishScriptTpl, self._dryRun, **kw)
    if rv == 0:
      self._countChanges += 1
    else:
      self._cleanup(arch, pkgName, pkgVer)
    return rv

  def _cleanup(self, arch, pkgName, pkgVer):
    kw = self._kw(None, arch, pkgName, pkgVer)
    debug(format("%(repo)s: cleaning up %(pkgdir)s and %(modulefile)s", **kw))
    rmrf(kw["pkgdir"])
    rmrf(kw["modulefile"])

  def transaction(self):
    if self._inCvmfsTransaction:
      debug(format("%(repo)s: already in a transaction", repo=self._repository))
      return True
    elif self._dryRun:
      info(format("%(repo)s: started transaction (dry run)", repo=self._repository))
      self._inCvmfsTransaction = True
      return True
    else:
      if execute([ "cvmfs_server", "transaction", self._repository ]) == 0:
        info(format("%(repo)s: started transaction", repo=self._repository))
        self._inCvmfsTransaction = True
        return True
      error(format("%(repo)s: cannot commence transaction: maybe another one is in progress?",
                   repo=self._repository))
      return False

  def abort(self, force=False):
    if not self._inCvmfsTransaction and not force:
      debug(format("%(repo)s: no transaction to abort", repo=self._repository))
      return True
    if self._dryRun and not force:
      info(format("%(repo)s: transaction aborted (dry run)", repo=self._repository))
      self._inCvmfsTransaction = False
      return True
    rv = execute([ "cvmfs_server", "abort", "-f", self._repository ])
    if rv == 0:
      info(format("%(repo)s: transaction aborted", repo=self._repository))
      self._inCvmfsTransaction = False
      return True
    error(format("%(repo)s: cannot abort transaction", repo=self._repository))
    return False

  def publish(self):
    if not self._inCvmfsTransaction:
      debug(format("%(repo)s: not in a transaction", repo=self._repository))
      return True
    if not self._countChanges:
      debug(format("%(repo)s: nothing to publish, cancelling transaction", repo=self._repository))
      return self.abort()
    info(format("%(repo)s: publishing transaction, %(npkg)d new package(s)",
                repo=self._repository, npkg=self._countChanges))
    if self._dryRun:
      info(format("%(repo)s: transaction published (dry run)", repo=self._repository))
      return True
    rv = execute([ "cvmfs_server", "publish", self._repository ])
    if rv == 0:
      info(format("%(repo)s: transaction published!", repo=self._repository))
      self._inCvmfsTransaction = False
      return True
    else:
      error(format("%(repo)s: cannot publish CVMFS transaction, aborting",
            repo=self._repository))
      self.abort()
      return False

class AliEnPackMan(object):

  def __init__(self, publishScriptTpl, dryRun=False):
    self._dryRun = dryRun
    self._publishScriptTpl = publishScriptTpl
    self._packs = None
    self._cachedArchs = []

  def _kw(self, url, arch, pkgName, pkgVer, deps):
    kw =  { "url": url, "package": pkgName, "version": pkgVer, "arch": arch, "dependencies": deps }
    return kw

  def installed(self, arch, pkgName, pkgVer):
    kw = self._kw(None, arch, pkgName, pkgVer, None)
    debug(format("PackMan: checking if %(package)s %(version)s is installed for %(arch)s", **kw))

    if self._packs is None:
      self._packs = {}
      for line in grabOutput([ "alien", "-exec",
                               "packman", "list", "-all", "-force" ])[1].split("\n"):
        m = search(r"VO_ALICE@(.+?)::([^\s]+)", line)
        if not m: continue
        pkg = m.group(1)
        ver = m.group(2)
        if not pkg in self._packs:
          self._packs[pkg] = {}
        self._packs[pkg].update({ver: []})

    if not arch in self._cachedArchs:
      for line in grabOutput([ "alien", "-exec", "find", "/alice/packages", arch ])[1].split("\n"):
        m = search(r"^/alice/packages/([^/]+)/([^/]+)/", line)
        if not m: continue
        pkg = m.group(1)
        ver = m.group(2)
        if not pkg in self._packs: continue
        self._packs[pkg].get(ver, []).append(arch)
      self._cachedArchs.append(arch)

    return arch in self._packs.get(pkgName, {}).get(pkgVer, [])

  def install(self, url, arch, pkgName, pkgVer, deps, allDeps):
    kw = self._kw(url, arch, pkgName, pkgVer,
                  ",".join(["VO_ALICE@"+x["name"]+"::"+x["ver"] for x in deps]))
    return runInstallScript(self._publishScriptTpl, self._dryRun, **kw)

  def transaction(self):
    # Not actually opening a "transaction", but failing if AliEn appears down.
    # If we don't fail here, package list appears empty and we'll attempt to
    # publish *every* package, and failing...
    _,out = grabOutput([ "alien", "-exec", "ls", "/alice/packages" ])
    if "AliRoot" in out.split("\n"):
      debug("PackMan: AliEn connection and APIs appear to work")
      return True
    error("PackMan: API response incorrect, assuming AliEn is not working at the moment")
    return False

  def abort(self, force=False):
    return True

  def publish(self):
    return True

class RPM(object):

  def __init__(self, repoDir, publishScriptTpl, dryRun=False):
    self._dryRun = dryRun
    self._repoDir = repoDir
    self._publishScriptTpl = publishScriptTpl
    self._countChanges = 0
    self._archs = []

  def _kw(self, url, arch, pkgName, pkgVer, workDir=None, deps=None):
    kw =  { "url": url, "package": pkgName, "version": pkgVer, "arch": arch, "dependencies": deps,
            "repodir": self._repoDir+"/"+arch, "workdir": workDir }
    kw.update({ "rpm": format("alisw-%(package)s+%(version)s-1-1.%(arch)s.rpm", **kw) })
    return kw

  def installed(self, arch, pkgName, pkgVer):
    kw = self._kw(None, arch, pkgName, pkgVer)
    debug(format("RPM: checking if %(rpm)s exists for %(package)s %(version)s on %(arch)s", **kw))
    return isfile(format("%(repodir)s/%(rpm)s", **kw))

  def install(self, url, arch, pkgName, pkgVer, deps, allDeps):
    workDir = mkdtemp(prefix="aliPublish-RPM-")
    kw = self._kw(url, arch, pkgName, pkgVer, workDir,
                  " ".join(["alisw-%s+%s" % (x["name"], x["ver"]) for x in deps]))
    debug(format("RPM: created temporary working directory %(workdir)s", **kw))
    rv = runInstallScript(self._publishScriptTpl, self._dryRun, **kw)
    if rv == 0:
      if not arch in self._archs:
        self._archs.append(arch)
      self._countChanges += 1
    debug(format("RPM: removing temporary working directory %(workdir)s", **kw))
    rmrf(workDir)
    return rv

  def transaction(self):
    return True

  def abort(self, force=False):
    return True

  def publish(self):
    if self._countChanges > 0:
      info(format("RPM: updating repository data, %(npkgs)s new package(s)",
           npkgs=self._countChanges))
      if not self._dryRun:
        for arch in self._archs:
          if execute([ "createrepo", self._repoDir+"/"+arch ]) == 0:
            info(format("RPM: repository updated for %(arch)s", arch=arch))
          else:
            error(format("RPM: error updating repository for %(arch)s", arch=arch))
            return False
        return True
      elif self._dryRun:
        info("RPM: not updating repository, dry run")
        return True
      else:
        error("RPM: error updating repository")
        return False
    debug("RPM: nothing new to publish")
    return True

def nameVerFromTar(tar, arch, validPacks):
  for pkgName in validPacks:
    vre = format("^(%(pack)s)-(.*?)(\.%(arch)s\.tar\.gz)?$", pack=escape(pkgName), arch=arch)
    vm = search(vre, tar)
    if vm:
      return { "name": vm.group(1), "ver": vm.group(2) }
  return None

def sync(pub, architectures, baseUrl, rules, includeFirst, autoIncludeDeps,
         notifEmail, riemann, dryRun):

  newPackages = {}

  # Template URLs
  packNamesUrlTpl = "%(baseUrl)s/%(arch)s/dist-direct"
  distUrlTpl = "%(baseUrl)s/%(arch)s/dist/%(pack)s/%(pack)s-%(ver)s"
  distDirectUrlTpl = "%(baseUrl)s/%(arch)s/dist-direct/%(pack)s/%(pack)s-%(ver)s"
  distRuntimeUrlTpl = "%(baseUrl)s/%(arch)s/dist-runtime/%(pack)s/%(pack)s-%(ver)s"
  verUrlTpl = "%(baseUrl)s/%(arch)s/dist-direct/%(pack)s"
  getPackUrlTpl = distDirectUrlTpl + "/%(pack)s-%(ver)s.%(arch)s.tar.gz"

  # Prepare the list of packages to install
  for arch in architectures:
    newPackages[arch] = []
    packNamesUrl = format(packNamesUrlTpl,
                          baseUrl=baseUrl, arch=arch)

    # Get valid package names for this architecture
    debug(format("Getting packages for architecture %(arch)s from %(url)s",
                 arch=arch, url=packNamesUrl))
    distPackages = [ p["name"] for p in jget(packNamesUrl) if p["type"] == "directory" ]
    distPackages.sort(key=lambda p: -len(p))
    debug("Packages found: %s" % ", ".join([p for p in distPackages]))

    # Packages to publish
    pubPackages = []

    # Get versions for all valid packages and filter them according to the rules
    for pkgName in distPackages:
      verUrl = format(verUrlTpl,
                      baseUrl=baseUrl, arch=arch, pack=pkgName)
      debug(format("%(arch)s / %(pack)s: listing versions under %(url)s",
                   arch=arch, pack=pkgName, url=verUrl))
      for pkgTar in jget(verUrl):
        if pkgTar["type"] != "directory":
          continue
        nameVer = nameVerFromTar(pkgTar["name"], arch, [pkgName])
        if nameVer is None:
          continue
        pkgVer = nameVer["ver"]
        # Here we decide whether to include/exclude it
        if not applyFilter(pkgVer,
                           rules["include"][arch].get(pkgName, None),
                           rules["exclude"][arch].get(pkgName, None),
                           includeFirst):
          debug(format("%(arch)s / %(pack)s / %(ver)s: excluded",
                arch=arch, pack=pkgName, ver=pkgVer))
          continue

        if not autoIncludeDeps:
          # Not automatically including dependencies, add this package only.
          # Not checking for dups because we can't have any
          pubPackages.append({ "name": pkgName, "ver": pkgVer })
          continue

        # At this point we have filtered in the package: let's see its dependencies!
        # Note that a package always depends on itself (list cannot be empty).
        distUrl = format(distRuntimeUrlTpl,
                         baseUrl=baseUrl, arch=arch, pack=pkgName, ver=pkgVer)
        runtimeDeps = jget(distUrl)
        if not runtimeDeps:
          error(format("%(arch)s / %(pack)s / %(ver)s: cannot list dependencies from %(url)s: skipping",
                       arch=arch, pack=pkgName, ver=pkgVer, url=distUrl))
          continue
        debug(format("%(arch)s / %(pack)s / %(ver)s: listing all dependencies under %(url)s",
                     arch=arch, pack=pkgName, ver=pkgVer, url=distUrl))
        for depTar in runtimeDeps:
          if depTar["type"] != "file":
            continue
          depNameVer = nameVerFromTar(depTar["name"], arch, distPackages)
          if depNameVer is None:
            continue
          depName = depNameVer["name"]
          depVer = depNameVer["ver"]
          # Append only if it does not exist yet
          if len([p for p in pubPackages if p["name"]==depName and p["ver"]==depVer]) == 0:
            debug(format("%(arch)s / %(pack)s / %(ver)s: adding %(depName)s %(depVer)s to publish",
                  arch=arch, pack=pkgName, ver=pkgVer, url=distUrl,
                  depName=depName, depVer=depVer))
            pubPackages.append({ "name": depName, "ver": depVer })

    pubPackages.sort(key=lambda itm: itm["name"])
    debug(format("%(arch)s: %(npacks)d package(s) candidate for publication: %(packs)s",
                 arch=arch, npacks=len(pubPackages),
                 packs=", ".join([p["name"]+" "+p["ver"] for p in pubPackages])))

    # Packages installation
    for pack in pubPackages:
      pkgUrl = format(getPackUrlTpl,
                       baseUrl=baseUrl, arch=arch, pack=pack["name"], ver=pack["ver"])

      if pub.installed(architectures[arch], pack["name"], pack["ver"]):
        debug(format("%(arch)s / %(pack)s / %(ver)s: already installed: skipping",
                     arch=arch, pack=pack["name"], ver=pack["ver"]))
        continue

      # Get direct and indirect dependencies
      deps = {}
      depUrlTpls = { "dist": distUrlTpl,
                     "dist-direct": distDirectUrlTpl,
                     "dist-runtime": distRuntimeUrlTpl }
      depFail = False
      for key,depsUrlTpl in depUrlTpls.iteritems():
        depsUrl = format(depsUrlTpl,
                         baseUrl=baseUrl, arch=arch, pack=pack["name"], ver=pack["ver"])
        debug(format("%(arch)s / %(pack)s / %(ver)s: listing %(key)s dependencies from %(url)s",
                     arch=arch, pack=pack["name"], ver=pack["ver"], key=key, url=depsUrl))
        jdeps = jget(depsUrl)
        if not jdeps:
          error(format("%(arch)s / %(pack)s / %(ver)s: cannot get %(dtype) dependencies: skipping",
                       arch=arch, pack=pack["name"], ver=pack["ver"], dtype=key))
          newPackages[arch].append({ "name": pack["name"], "ver": pack["ver"], "success": False })
          depFail = True
          break
        deps[key] = [ nameVerFromTar(x["name"], arch, distPackages)
                      for x in jdeps if x["type"] == "file" ]
        deps[key] = [ x for x in deps[key] if (x is not None and
                                               x["name"] != pack["name"]) ]
      if depFail:
        continue
      # dist-direct-runtime: all entries in dist-direct but not in dist-runtime
      deps["dist-direct-runtime"] = [ x for x in deps["dist-direct"]
                                      if [ 1 for y in deps["dist-runtime"]
                                           if x["name"] == y["name"] ] ]

      # Here we can attempt the installation
      info(format("%(arch)s / %(pack)s / %(ver)s: getting and installing",
                  arch=arch, pack=pack["name"], ver=pack["ver"]))
      info(" * Source: %s" % pkgUrl)
      info(" * Direct deps: %s" % ", ".join([i["name"]+" "+i["ver"] for i in deps["dist-direct"]]))
      info(" * All deps: %s" % ", ".join([i["name"]+" "+i["ver"] for i in deps["dist"]]))
      info(" * Direct runtime deps: %s" % ", ".join([i["name"]+" "+i["ver"] for i in deps["dist-direct-runtime"]]))
      info(" * Runtime deps: %s" % ", ".join([i["name"]+" "+i["ver"] for i in deps["dist-runtime"]]))

      if not pub.transaction():
        sys.exit(2)  # fatal
      else:
        if riemann: riemann.notify("warning", arch, pack["name"], pack["ver"])
        rv = pub.install(pkgUrl, architectures[arch], pack["name"], pack["ver"],
                         deps["dist-direct-runtime"], deps["dist-runtime"])
        newPackages[arch].append({ "name": pack["name"],
                                   "ver": pack["ver"],
                                   "success": (rv==0),
                                   "deps": deps["dist-direct-runtime"],
                                   "alldeps": deps["dist-runtime"] })
      if rv == 0:
        info(format("%(arch)s / %(pack)s / %(ver)s: installed successfully",
                     arch=arch, pack=pack["name"], ver=pack["ver"]))
        if riemann: riemann.notify("ok", arch, pack["name"], pack["ver"])
      else:
        error(format("%(arch)s / %(pack)s / %(ver)s: publish script failed with %(rv)d",
                     arch=arch, pack=pack["name"], ver=pack["ver"], rv=rv))
        if riemann: riemann.notify("critical", arch, pack["name"], pack["ver"])

  # Publish eventually
  if pub.publish():
    totSuccess = 0
    totFail = 0
    for arch,packStatus in newPackages.iteritems():
      nSuccess = sum([1 for x in packStatus if x["success"]])
      nFail = len(packStatus) - nSuccess
      totSuccess = totSuccess + nSuccess
      totFail = totFail + nFail
      info(format("%(arch)s: install OK for %(nSuccess)d/%(nPacks)d package(s): %(successPacks)s",
           arch=arch,
           nSuccess=nSuccess,
           nPacks=len(packStatus),
           successPacks=", ".join([x["name"]+" "+x["ver"] for x in packStatus if x["success"]])))
      if nFail:
        error(format("%(arch)s: install failed for %(nFail)d/%(nPacks)d package(s): %(failedPacks)s",
              arch=arch,
              nFail=nFail,
              nPacks=len(packStatus),
              failedPacks=", ".join([x["name"]+" "+x["ver"] for x in packStatus if not x["success"]])))
    if notifEmail:
      notify(notifEmail, architectures, newPackages, dryRun)
    else:
      debug("No email notification configured")
    return totFail == 0 or totSuccess > 0

  return False

def notify(conf, archs, pack, dryRun):
  if not "server" in conf:
    return
  try:
    mailer = SMTP(conf["server"], conf.get("port", 25))
  except Exception as e:
    error("Email notification: cannot connect to %s" % conf["server"])
    return
  for arch,packs in pack.iteritems():
    for p in packs:
      key = "success" if p["success"] else "failure"
      deps_fmt = "".join([ format(conf.get("package_format", "%(package)s %(version)s "),
                                   package=x["name"],
                                   version=x["ver"],
                                   arch=archs[arch]) for x in p.get("alldeps", []) ])
      kw =  { "package": p["name"],
              "version": p["ver"],
              "arch": archs[arch],
              "dependencies_fmt":
                "".join([
                          format(conf.get("package_format", "%(package)s %(version)s "),
                                 package=x["name"], version=x["ver"], arch=archs[arch])
                          for x in p.get("deps", [])
                 ]),
              "alldependencies_fmt":
                "".join([
                          format(conf.get("package_format", "%(package)s %(version)s "),
                                 package=x["name"], version=x["ver"], arch=archs[arch])
                          for x in p.get("alldeps", [])
                ])
            }

      body = format(conf.get(key, {}).get("body", ""), **kw)
      subj = format(conf.get(key, {}).get("subject", "%(package)s %(version)s: "+key), **kw)

      to = conf.get(key, {}).get("to", "")
      if isinstance(to, dict):
        to = to.get(p["name"], to.get("default", ""))
      if isinstance(to, list):
        to = ",".join(to)
      to = [ x.strip() for x in to.split(",") ] if to else []

      sender = format(conf.get(key, {}).get("from", "noreply@localhost"), **kw)
      if body == "" or not to:
        debug(format("Not sending email notification for %(package)s %(version)s (%(arch)s)",
                     package=p["name"], version=p["ver"], arch=archs[arch]))
        continue
      body = ("Subject: %s\nFrom: %s\nTo: %s\n\n" % (subj, sender, ", ".join(to))) + body
      if dryRun:
        debug(format("Notification email for %(package)s %(version)s (%(arch)s) follows:\n%(body)s",
                     package=p["name"], version=p["ver"], arch=archs[arch], body=body))
      else:
        try:
          mailer.sendmail(sender, to, body)
          debug(format("Sent email notification for %(package)s %(version)s (%(arch)s)",
                       package=p["name"], version=p["ver"], arch=archs[arch]))
        except Exception as e:
          error(format("Cannot send email notification for %(package)s %(version)s (%(arch)s)",
                       package=p["name"], version=p["ver"], arch=archs[arch]))

def hostport(s, defaultPort):
  host = s.split(":", 1)
  try:
    port = len(host) == 2 and int(host[1]) or defaultPort
  except ValueError:
    port = defaultPort
  host = host[0]
  return host,port

def mesos_resolve(host, dns):
  for d in sorted(dns, key=lambda k: random()):
    ips = [ x["ip"] for x in jget(format("http://%(dns)s/v1/hosts/%(host)s", dns=d, host=host))
                    if x.get("ip", None) ]
    if ips:
      return ips
  return [host]  # fallback to input on error

def main():
  parser = ArgumentParser()
  parser.add_argument("action")
  parser.add_argument("--pkgname", dest="pkgName")
  parser.add_argument("--pkgver", dest="pkgVer")
  parser.add_argument("--pkgarch", dest="pkgArch")
  parser.add_argument("--config", "-c", dest="configFile", default="aliPublish.conf",
                      help="Configuration file")
  parser.add_argument("--debug", "-d", dest="debug", action="store_true", default=False,
                      help="Debug output")
  parser.add_argument("--abort-at-start", dest="abort", action="store_true", default=False,
                      help="Abort any pending CVMFS transaction at start")
  parser.add_argument("--no-notification", dest="notify", action="store_false", default=True,
                      help="Do not send any notification (ignore configuration)")
  parser.add_argument("--dry-run", "-n", dest="dryRun", action="store_true", default=False,
                      help="Do not write or publish anything")
  args = parser.parse_args()
  
  logger = logging.getLogger()
  loggerHandler = logging.StreamHandler()
  logger.addHandler(loggerHandler)

  loggerHandler.setFormatter(logging.Formatter('%(levelname)-5s: %(message)s'))
  if args.debug: logger.setLevel(logging.DEBUG)
  else: logger.setLevel(logging.INFO)

  logging.getLogger("requests").setLevel(logging.WARNING)
  logging.getLogger("urllib3").setLevel(logging.WARNING)

  progDir = dirname(realpath(__file__))

  try:
    debug(format("Reading configuration from %(configFile)s (current directory: %(curDir)s)",
                 configFile=args.configFile, curDir=getcwd()))
    with open(args.configFile, "r") as cf:
      conf = yaml.safe_load(cf.read())
  except (IOError, YAMLError) as e:
    error(format("While reading %(configFile)s: " + str(e), configFile=args.configFile))
    sys.exit(1)

  if conf is None: conf = {}
  if conf.get("include", None) is None: conf["include"] = {}
  if conf.get("exclude", None) is None: conf["exclude"] = {}

  doExit = False

  conf["mesos_dns"] = [ ":".join(map(str, hostport(x, 8123))) for x in conf.get("mesos_dns", []) ]
  conf["riemann_host"],conf["riemann_port"] = hostport(conf.get("riemann_host", ""), 5555)

  # Resolve Riemann name via Mesos
  if conf["riemann_host"].endswith(".mesos") and conf["mesos_dns"]:
    conf["riemann_host"] = choice(mesos_resolve(conf["riemann_host"], conf["mesos_dns"]))

  if not isinstance(conf.get("architectures", None), dict):
    error("architectures must be a dict of dicts")
    doExit = True
  if not isinstance(conf.get("base_url", None), basestring):
    error("base_url must be a string")
    doExit = True
  conf["auto_include_deps"] = conf.get("auto_include_deps", False)
  if not isinstance(conf["auto_include_deps"], bool):
    error("auto_include_deps must be a boolean")
    doExit = True
  conf["notification_email"] = conf.get("notification_email", {}) if args.notify else {}
  if not isinstance(conf["notification_email"], dict):
    error("notification_email must be a dict of dicts")
    doExit = True

  if doExit: exit(1)

  # Resolve base_url name via Mesos
  us = urlsplit(conf["base_url"])
  if us.netloc.endswith(".mesos") and conf["mesos_dns"]:
    us = us._replace( netloc=choice(mesos_resolve(us.netloc, conf["mesos_dns"])) )
    conf["base_url"] = urlunsplit(us)

  debug("Configuration: " + json.dumps(conf, indent=2))
  incexc = conf.get("filter_order", "include,exclude")
  if incexc == "include,exclude": includeFirst = True
  elif incexc == "exclude,include": includeFirst = False
  else:
    error("filter_order can be include,exclude or exclude,include")
    sys.exit(1)

  rules = { "include": {}, "exclude": {} }
  for arch,maps in conf["architectures"].iteritems():
    for r in rules.keys():
      rules[r][arch] = isinstance(maps, dict) and maps.get(r, {}) or {}
      for uk in set(conf[r].keys()+rules[r][arch].keys()):
        a = rules[r][arch].get(uk, [])
        b = conf[r].get(uk, [])
        rules[r][arch][uk] = (a == True or b == True) or (a + b)
  debug("Per architecture include/exclude rules: %s" % json.dumps(rules, indent=2))

  if args.action in [ "sync-cvmfs", "sync-alien", "sync-rpms" ]:
    chdir("/")
    if args.action == "sync-cvmfs":
      if not isinstance(conf.get("cvmfs_repository", None), basestring):
        error("cvmfs_repository must be a string")
        doExit = True
      if not isinstance(conf.get("cvmfs_package_dir", None), basestring):
        error("cvmfs_package_dir must be a string")
        doExit = True
      if not isinstance(conf.get("cvmfs_modulefile", None), basestring):
        error("cvmfs_modulefile must be a string")
        doExit = True
      if doExit: sys.exit(1)
      archKey = "CVMFS"
      pub = CvmfsServer(repository=conf["cvmfs_repository"],
                        modulefileTpl=conf["cvmfs_modulefile"],
                        pkgdirTpl=conf["cvmfs_package_dir"],
                        publishScriptTpl=open(progDir+"/pub-cvmfs-template.sh").read(),
                        dryRun=args.dryRun)
    elif args.action == "sync-alien":
      archKey = "AliEn"
      pub = AliEnPackMan(publishScriptTpl=open(progDir+"/pub-alien-template.sh").read(),
                         dryRun=args.dryRun)
    else:
      if not isinstance(conf.get("rpm_repo_dir", None), basestring):
        error("rpm_repo_dir must be a string")
        sys.exit(1)
      archKey = "RPM"
      pub = RPM(repoDir=conf["rpm_repo_dir"],
                publishScriptTpl=open(progDir+"/pub-rpms-template.sh").read(),
                dryRun=args.dryRun)
    if args.abort:
      pub.abort(force=True)

    architectures = dict((arch, isinstance(maps, dict) and maps.get(archKey, arch) or arch)
                         for (arch,maps) in conf["architectures"].iteritems())
    debug("Architecture names mappings: %s" % json.dumps(architectures, indent=2))
    debug(args.dryRun)
    riemann = None if args.dryRun \
              else RiemannPkgNotify(conf["riemann_host"], conf["riemann_port"])
    sync(pub=pub,
         architectures=architectures,
         baseUrl=conf["base_url"],
         rules=rules,
         includeFirst=includeFirst,
         autoIncludeDeps=conf["auto_include_deps"],
         notifEmail=conf["notification_email"],
         riemann=riemann,
         dryRun=args.dryRun) and sys.exit(0) or sys.exit(1)
  elif args.action == "test-rules":
    if not args.pkgName or not args.pkgVer or not args.pkgArch:
      error("Please specify a package name, version and architecture")
      sys.exit(1)
    matches = applyFilter(args.pkgVer,
                          rules["include"].get(args.pkgArch, {}).get(args.pkgName, None),
                          rules["exclude"].get(args.pkgArch, {}).get(args.pkgName, None),
                          includeFirst)
    info(format(matches and "%(package)s version %(version)s matches filters"
                        or "%(package)s version %(version)s does NOT match filters",
                package=args.pkgName, version=args.pkgVer))
    sys.exit(not matches)
  else:
    error("Wrong action, use: sync-cvmfs, sync-alien, sync-rpms, test-rules")
    sys.exit(1)

if __name__ == "__main__":
  main()
